{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "Downloading: 100%|██████████| 872k/872k [00:00<00:00, 4.72MB/s]\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.33kB/s]\n",
      "Downloading: 100%|██████████| 1.72M/1.72M [00:01<00:00, 1.15MB/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       843 comments\n",
      "   Min length: 236 tokens\n",
      "   Max length: 32,588 tokens\n",
      "Median length: 3,069.0 tokens\n",
      "839 of 843 sentences (99.5%) in the training set are longer than 500 tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joan/miniforge3/envs/python38/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAFgCAYAAADZ8V/cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABDlElEQVR4nO3deViU5f4/8PcMCgiMCki4K3oakH0M/bqCLILkLm6loKiZpglqpWRZekoTCwxUkhTL3aBcOmouiZWezAVLUXBFwF0hzQFlGe7fH/6Y4wjIsM3o+H5dl9fV3M89z3zm832O37f3s4xECCFARERERAZBqu8CiIiIiKj2MNwRERERGRCGOyIiIiIDwnBHREREZEAY7oiIiIgMCMMdERERkQFhuCOiGlMqlUhISMCQIUPwyiuvwN3dHUOHDsXmzZtRUlKi7/L0Ljs7u9I5wcHBsLe310E11adUKpGbm6t+PXv27Ge+ZqIXEcMdEdXIpUuXEBQUhKioKNjb22PGjBmYNm0aTExMMHfuXLz33nt4kR+nuXz5cowbN07fZdRYamoqAgMDcf78eX2XQkSVqKfvAojo+VVQUIC33noLd+/eRVJSEhwcHNTbxo0bh3nz5mHDhg1wdXVFSEiIHivVn99//x0qlUrfZdTYuXPncOvWLX2XQURa4ModEVXbhg0bkJGRgYiICI1gV2rWrFlo1KgRNm3apIfqiIheTAx3RFRtO3bsgJmZGfr27VvudlNTU3z33XfYunWrxvixY8cwduxYKBQKKBQKhISE4OjRoxpzfHx8MH/+fCQmJiIgIACurq4ICgrCyZMncfv2bYSFhUGhUKBnz56Ijo7WuLbP3t4eX3/9NeLj49GrVy+4ubkhODgYmZmZyMjIwPjx4+Hu7g4fHx+sWbOmTN0//PADBg0aBBcXF3Tp0gWzZ8/WWLW6cuUK7O3tsXXrVkRHR8PT0xMuLi4YNmwYDh8+rPEdjhw5gqtXr8Le3h6xsbHVaXMZJ06cQGhoqLp/48aNw8mTJ8v0b+7cudi2bRv69u0LFxcX+Pv7Y/369WX298svv2DYsGFwd3eHr68v1q1bhzlz5sDHxwcAEBsbi4iICABASEiIerzUqVOnEBwcDFdXV3Tv3h0LFixAQUGBersQAkuXLkVAQABcXFzQrVs3vPvuu7h+/Xqt9IOINEn427JEVB1CCDg7O6Njx45Yu3at1u/7+eefMXXqVLRu3RpBQUEAgMTERFy7dg0xMTHw9fUF8CicqFQqqFQqjBkzBkIIxMXFoWHDhpDJZHj55ZfRpUsX7NmzBwcPHsRnn32GwYMHA3gU7mxtbdGgQQOMGjUKOTk5WLlyJdq3b4+7d++iV69ecHR0RGJiIlJTU7F27Vp07twZALB06VLExsYiICAAXbp0wc2bN7Fu3To0atQISUlJsLKywpUrV+Dr64vmzZujQYMGGD58OIqKipCQkID8/HwcOHAAlpaW2LdvH7744gv8/fffiIiIgL29fbkrnMCjGyqOHDmCs2fPPrV/hw4dwptvvgkHBwf069cPhYWF+OGHH3D16lWsXr0aHh4e6v4JIZCXl4fRo0ejSZMm2Lx5M9LT0xEfHw8vLy8AQHJyMqZMmQK5XI7Bgwfj5s2bWLt2LczMzGBubo79+/cjPT0dGzZswObNmzFp0iS4uLjAz88Ps2fPxpYtW2Bubo4BAwbAwcEBBw4cQHJyMkJCQjBnzhwAQFxcHGJiYjBq1CjY29vjypUrWLNmDZo2bYr//Oc/MDIy0vr4ISItCCKiasjJyRFyuVxMnz5d6/cUFRUJT09P4eXlJe7fv68ev3fvnujZs6fo2bOnKCwsFEII4e3tLezt7UV6erp63qJFi4RcLhfh4eHqsby8POHk5CRmzJihHpPL5cLNzU3cvn1bPTZt2jQhl8vF4sWL1WOXL18WcrlcREVFCSGEyMrKEg4ODuLzzz/XqPvs2bPCyclJfPrpp0IIIbKzs4VcLhdeXl4iLy9PPW/Hjh1CLpeLzZs3q8dGjx4tvL29K+3N6NGjhVwuf+oclUolfH19xciRI0VxcbFGD3r37i0GDhyoHivtX1pamnrs1q1bwt7eXqNXfn5+wt/fXzx48EA9tnfvXiGXyzXq/v7774VcLheHDx9Wj82aNUvI5XKxevVqjRp79+4tvLy81GOBgYFi4sSJGt9l48aNYsCAASIzM/Op35mIqo6nZYmoWqTSR399VOVmgTNnzuDGjRsYNWoULCws1OMNGzbE6NGjcfPmTaSmpqrHW7durfGoDTs7OwBA79691WNmZmawtrbG7du3NT5LoVCgSZMm6tdt27Yt896WLVsCgPqU6969e1FSUgIfHx/k5uaq/zRp0gQdOnTAgQMHND7Dy8sLZmZm6telq3JP1lJbzpw5g+zsbPj5+eHevXvq+h4+fAhvb2+kpaXhxo0b6vl2dnYaK4U2NjZo0qQJ7ty5AwBIT09HVlYWRo4cCVNTU/U8Pz8/tG/fXuu6Hj8tL5VK4ejoqP4MAGjatCn++OMPfPvtt+rxkSNHYtu2bWjdunXVG0FET8W7ZYmoWho1aoT69etrPPesMleuXAHwv5D2uHbt2gEArl27BoVCAQCwtrbWmFN6+s7KyqrMuHjiCpMn31uvXr0y7y3dX+l7s7KyADwKHuWpX7++xusn6zA2NgaAOnu2X2l9kZGRiIyMLHfO9evX0bRp03LrK62xtL7MzEwAQJs2bcrMs7OzQ1pamlZ1PdlrU1NTFBUVqV+/9957mDx5MhYsWICFCxfCyckJPj4+GD58OGxsbLT6DCLSHsMdEVWLRCKBQqFAamoqiouL1eHpSdHR0cjOzkZERMRTn3dXuu3xAFXRPiUSSaX1Vee9paEnLi5OYyWrIqWrl7pSWl9YWBjc3d3LnVMakoHK6ysuLgbwv1D6OBMTE63rquxzHBwcsHv3bvz2229ITk7Gb7/9hpiYGHzzzTfYtGlTlVYJiahyDHdEVG29e/fGkSNHsHPnTgwYMKDM9ocPHyIpKQkqlQqNGzdGixYtADx68PGTMjIyAEC96qQPpfU1a9YMHTp00Nj2yy+/aJxK1ofS+szMzNCtWzeNbSdPnsS9e/e0CqWlWrVqBQC4fPkyevToobHt8uXLNSv2/1OpVEhPT4eFhQV8fX3VN8zs3LkT06dPR2JiImbPnl0rn0VEj/CaOyKqthEjRqBFixZYtGgRzp07p7FNpVLh448/xp07d/DGG2+gfv36cHJygo2NDTZu3AilUqmeq1QqsWHDBtjY2MDZ2VnXX0PN29sbALBixQqNVca0tDRMnjwZ3377bZX3KZVKa+00rbOzM2xsbLB27Vrk5eWpx5VKJcLDwxEREVGlO0+dnZ3RrFkzJCUlobCwUD3+559/4syZMxpzS1fnqvpdVCoVQkJCsGDBAo1xNzc3jf0SUe3hyh0RVZuJiQmWLl2KcePGYejQoejfvz9cXFxw9+5d/PTTT0hLS0OfPn0QGhoK4NEp1w8//BDh4eEICgrC0KFDAQBJSUm4desWYmJi9Pr/7OVyOYKDg7F27VrcvXsXfn5+uHv3LtatWwdzc3OEhYVVeZ9WVlY4evQoVq9ejY4dO6pDTUXmzp1b7vjrr78OBwcHdf+GDBmCoUOHwsTERP0omc8//7zC09HlkUqlmD17NsLDwzFy5EgMHDgQubm5WLNmTZlTtaXX723cuBF37txB//79tfoMY2NjBAcHIy4uDlOmTEHPnj3x8OFDbN68GQ0aNFA/DoeIag/DHRHViKOjI7Zt24ZvvvkGv/76K3bu3AkhBOzt7bFgwQIMGTJE4zq3gIAAJCQkYPny5Vi2bBnq1asHNzc3fPrpp+pntOnTnDlz0K5dO2zatAmLFi2CTCaDh4cHwsLCqnVt2IQJE3D27Fl88cUXGDJkSKXhbvPmzeWOe3p6wsHBQd2/uLg4LF++HFKpFC+//DLi4uLUK49V0adPH0RHRyMuLg6LFy+Gra0tIiIisHXrVo2bZbp27YrAwEAkJyfj8OHD8Pf31/ozpk2bhsaNG+P777/HokWLYGRkhI4dO2Lx4sW83o6oDvAhxkRELyiVSoV79+6Ve1dt//790bBhw3J/0YKInm282IGI6AWlUqng6elZ5lTwuXPncP78ebi6uuqpMiKqCZ6WJSJ6QRkbG6NPnz5ISkqCRCKBs7Mzbt26hY0bN8LS0lJ9rSQRPV94WpaI6AX28OFDrFq1Ctu3b8f169chk8nQtWtXhIeHq3/Bg4ieLwx3RERERAaE19wRERERGRCGOyIiIiIDwhsqHvP333koKXn+z1JbW1sgJ0dZ+USqFey3brHfusV+6xb7rVvPa7+lUgksLc0r3M5w95iSEmEQ4Q6AwXyP5wX7rVvst26x37rFfuuWIfabp2WJiIiIDAjDHREREZEBYbgjIiIiMiAMd0REREQGhOGOiIiIyIAw3BEREREZEIY7IiIiIgPCcEdERERkQBjuiIiIiAwIf6GCiIiICEBxCVBQVFzj/ZjUr4d6elw+Y7gjIiIiwqNgdzTtZo3306mDLeqZ6C9i8bQsERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQvYe7jRs3IjAwEO7u7ujfvz+2b9+usf3gwYMICgqCm5sbfHx8kJCQUGYfp06dQnBwMBQKBXr06IGoqCgUFRXp6isQERERPTP0Gu42b96Mjz/+GL169cLy5cvRrVs3vPvuu9i1axcAICUlBZMmTUK7du0QGxuL/v37IzIyEqtWrVLvIzMzE2PHjoWJiQmWLFmCcePGYfXq1Vi4cKG+vhYRERGR3uj1OXdbtmzB//3f/2HWrFkAgG7duiE1NRUbNmxAYGAgYmJi4OjoiMWLFwMAPD09UVxcjK+++grBwcEwNjZGfHw8ZDIZli9fDmNjY3h5ecHU1BSffPIJ3nzzTdja2urzKxIRERHplF5X7goKCmBubq4x1rhxY9y9excFBQU4duwY/P39NbYHBATgn3/+QUpKCgDg0KFD8Pb2hrGxsXpOnz59oFKpcPDgwbr/EkRERETPEL2Gu5CQEPz222/YtWsXlEolfvrpJxw4cAADBw5EdnY2ioqKYGdnp/GeNm3aAAAyMjLw4MEDXL9+vcwcKysrWFhYICMjQ2ffhYiIiOhZoNfTsn379sXhw4cRHh6uHhs8eDAmTJiAEydOAAAsLCw03lO60qdUKnH//v1y55TOUyqVVarH2rrsfp5XNjYyfZfwQmG/dYv91i32W7fYb916vN8iNx8yC9Ma79PMzAQ2VmY13k916TXcTZ48GSdOnEBERAQcHR3x119/Yfny5bCwsMCrr74KAJBIJOW+VyqVQghR4RwhBKTSqi1M5uQoUVIiqvgtnj02NjLcvn1f32W8MNhv3WK/dYv91i32W7ee7Hd+QTHuKx/WeL/5+QW4rVLVeD8VkUolT12Q0lu4S0lJwcGDB7Fw4UIMGTIEANC5c2c0bNgQc+fOxdChQwGgzOpb6WuZTKZesStvhS4/Px8yGf/1Q0RERC8WvV1zd+3aNQBAx44dNcY9PDwAAGlpaTAyMkJWVpbG9tLXdnZ2MDc3h62tLTIzMzXm5OTkQKlUlrkWj4iIiMjQ6S3clQavo0ePaoz/+eefAIB27drBw8MDe/bsUZ9+BYDdu3dDJpPB2dkZANC9e3ckJyejsLBQY46RkRE6d+5cx9+CiIiI6Nmit9OyTk5O8PPzw4IFC5CXl4cOHTogNTUVy5Ytg6enJ9zc3DB58mSEhoZi+vTpGDx4ME6cOIFVq1Zh5syZaNCgAQBgwoQJ2LFjByZOnIgxY8bg8uXLiIqKwvDhw9G8eXN9fT0iIiIivZCIx5fFdKywsBBLly7F9u3bkZOTgxYtWqBfv36YOHGi+rl1e/fuRUxMDDIyMmBra4tRo0Zh3LhxGvs5duwYIiMjkZaWBktLSwwaNAhvv/026tevX6V6eEMFVQf7rVvst26x37rFfuvWk/3OKyjG0bSbNd5vpw62MDepu/Wzym6o0Gu4e9Yw3FF1sN+6xX7rFvutW+y3bhlquNPrQ4yJiIiIqHYx3BEREREZEIY7IiIiIgPCcEdERERkQBjuiIiIiAwIwx0RERGRAWG4IyIiIjIgDHdEREREBoThjoiIiMiAMNwRERERGRCGOyIiIiIDwnBHREREZEAY7oiIiIgMCMMdERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQhjsiIiIiA8JwR0RERGRAGO6IiIiIDAjDHREREZEBYbgjIiIiMiAMd0REREQGhOGOiIiIyIAw3BEREREZEIY7IiIiIgPCcEdERERkQBjuiIiIiAwIwx0RERGRAWG4IyIiIjIgDHdEREREBoThjoiIiMiAMNwRERERGRCGOyIiIiIDwnBHREREZEAY7oiIiIgMCMMdERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQhjsiIiIiA8JwR0RERGRAahzuzp8/j4sXL9ZGLURERERUQ1qHOyEE4uPjERERAQAoKSnBxIkTMWDAAPTr1w/jxo1DXl5enRVKRERERJXTOtytWrUKUVFRuHPnDgBg165d+PXXX+Hv748pU6bg+PHjWLZsWZ0VSkRERESVq6ftxC1btqB3796IjY0FAOzcuRMNGjTAokWLYGpqiry8PPz0009477336qxYIiIiIno6rVfusrOz4enpCQAoKirC77//js6dO8PU1BQA0L59e/WqHhERERHph9bhrmHDhlAqlQCAP/74A/n5+eqwBwBZWVlo0qRJlQs4evQoXnvtNbi5uaFHjx7497//rXHt3sGDBxEUFAQ3Nzf4+PggISGhzD5OnTqF4OBgKBQK9OjRA1FRUSgqKqpyLURERETPO61PyyoUCqxbtw4tWrTAV199hXr16sHf3x9FRUVITk7Gxo0b4efnV6UP//PPPxEaGgofHx/ExcUhMzMTUVFRyM3NRXR0NFJSUjBp0iQEBgYiLCwMx48fR2RkJIQQGD9+PAAgMzMTY8eOhUKhwJIlS3Dx4kVER0dDqVRi7ty5VesGERER0XNO63D3/vvvY/z48Zg2bRokEgnee+892NjY4I8//sC0adNgZ2eHsLCwKn34559/Dnd3d3z55ZeQSCTo1q0bSkpKsHr1ajx48AAxMTFwdHTE4sWLAQCenp4oLi7GV199heDgYBgbGyM+Ph4ymQzLly+HsbExvLy8YGpqik8++QRvvvkmbG1tq9YRIiIioueY1qdlmzVrhu3bt+O7777DgQMHEBoaCgBwcHBAVFQUfvjhBzRt2lTrD87NzcWxY8fw2muvQSKRqMdHjRqFffv2QSqV4tixY/D399d4X0BAAP755x+kpKQAAA4dOgRvb28YGxur5/Tp0wcqlQoHDx7Uuh4iIiIiQ6B1uFu6dCkuXboEV1dXjdWwRo0a4dVXX8X58+fx0Ucfaf3B586dgxACjRo1Qnh4ONzd3fHKK6/go48+wsOHD5GdnY2ioiLY2dlpvK9NmzYAgIyMDDx48ADXr18vM8fKygoWFhbIyMjQuh4iIiIiQ6D1admlS5eibdu2kMvl5W5PSUnBDz/8gHnz5mm1v9zcXADA7Nmz0bt3b8TFxeHs2bNYsmQJCgoKMGLECACAhYWFxvvMzc0BAEqlEvfv3y93Tum80htAtGVtXXY/zysbG5m+S3ihsN+6xX7rFvutW+y3bj3eb5GbD5mFaY33aWZmAhsrsxrvp7oqDHfZ2dkYP348VCqVemzBggWIjo4uM1cIgVu3bqFt27Zaf3Dp3awdO3ZUr/h17doVQggsWrQIw4cPBwCNU7aPk0qlEEJUOEcIAam0ar+ulpOjREmJqNJ7nkU2NjLcvn1f32W8MNhv3WK/dYv91i32W7ee7Hd+QTHuKx/WeL/5+QW4/Vh+qm1SqeSpC1IVhrtWrVph0KBB+P333wEAV69eRePGjWFtbV1mrpGREdzd3TFhwgStCytdgXv8cSoA0KNHD3z22Wc4deoUAJRZfSt9LZPJ1Ct25a3Q5efnQybjv36IiIjoxfLU07JvvfUW3nrrLQCAj48PZs6cCV9f31r54NJVvsLCQo3x0hW9li1bwsjICFlZWRrbS1/b2dnB3Nwctra2yMzM1JiTk5MDpVJZ5lo8IiIiIkOn9XnL/fv311qwAx79okWLFi2wc+dOjfHk5GTUq1cPCoUCHh4e2LNnj/r0KwDs3r0bMpkMzs7OAIDu3bsjOTlZIyTu3r0bRkZG6Ny5c63VS0RERPQ80PqGCgC4d+8e9uzZgzt37mhci1dKIpFgypQpWu1LIpHgnXfewYwZM/DOO+9gyJAhSE1NRVxcHIKDg2FlZYXJkycjNDQU06dPx+DBg3HixAmsWrUKM2fORIMGDQAAEyZMwI4dOzBx4kSMGTMGly9fRlRUFIYPH47mzZtX5esRERERPfck4vFlsaf4448/MGnSJDx8+BAVvUUikSAtLa1KBezbtw/Lli3DhQsXYG1tjREjRuDNN99U3wyxd+9exMTEICMjA7a2thg1ahTGjRunsY9jx44hMjISaWlpsLS0xKBBg/D222+jfv36VaqFN1RQdbDfusV+6xb7rVvst2492e+8gmIcTbtZ4/126mALc5MqrZ9VSWU3VGgd7oYPH44rV67ggw8+QIcOHTQeGvy4Fi1aVK/SZwDDHVUH+61b7Ldusd+6xX7rlqGGO60/OT09HWFhYXj11VdrpTAiIiIiqn1a31BhaWmJevXqLoUSERERUc1pHe4GDRqExMREFBQU1GU9RERERFQDWi/FtWvXDj/++CMCAwPh5eUFKyurMr8MUZW7ZYmIiIio9mkd7mbNmqX+740bN5Y7h+GOiIiISL+0Dnc///xzXdZBRERERLVA63D3PD/ihIiIiOhFofUNFQBw9+5dfPbZZwgICICbmxt+//13pKSkIDw8HJcvX66jEomIiIhIW1qHu9u3byMoKAjr1q1Do0aN1L/lev/+fezduxcjRozAxYsX66xQIiIiIqqc1uEuKioK9+7dw9atW/HVV1+pf4LMy8sLSUlJkEql+PLLL+usUCIiIiKqnNbh7sCBAxg9ejT+9a9/lXkESocOHTBq1CikpKTUeoFEREREpD2tw11eXh6aNm1a4XZLS0vcv8/fwyMiIiLSJ63DXfv27fHHH39UuH3fvn2ws7OrlaKIiIiIqHq0DnfBwcHYtWsXoqOjkZWVBQAoLCxEeno6ZsyYgcOHD2PkyJF1VigRERERVU7r59wNGTIE165dw/LlyxEfHw8AmDRpEgBACIHg4GCGOyIiIiI90zrcAcDUqVMxcOBA7N27F9nZ2VCpVGjZsiW8vb3x8ssv11WNRERERKSlKoU7AGjVqhXGjRtXF7UQERERUQ1VKdwdO3YMBw8exO3bt1FSUlJmu0QiwYIFC2qtOCIiIiKqGq3D3dq1a7FgwQL1w4vLw3BHREREpF9ah7tvvvkGzs7O+OKLL9CyZUtIpVX6WVoiIiIi0gGtE1pubi6GDRuG1q1bM9gRERERPaO0TmkdO3bE6dOn67IWIiIiIqohrU/LfvDBBxg7diyio6Ph6+sLa2vrMr8xCwDNmzev1QKJiIiISHtahzsjIyM0btwY8fHx6ocYlyctLa1WCiMiIiKiqqvSyt3FixcREBCAtm3bol69Kj8ij4iIiIjqmNYJ7eTJk5gwYQLCw8PrsBwiIiIiqgmtb6iwtLREkyZN6rIWIiIiIqohrcPda6+9hvXr1yM3N7cu6yEiIiKiGtD6tKxUKkV+fj58fX3RsWNHWFtbw8jISGMOf6GCiIiISL+0Dneff/65+r8PHTpU7hyGOyIiIiL90jrcpaen12UdRERERFQL+DtiRERERAakSg+r27p1Kw4dOoTbt2+jpKSkzHaJRIJvv/221oojIiIioqrROtxFR0djxYoVqF+/PqytrSGVctGPiIiI6FmjdbjbsmULevTogdjYWDRo0KAuayIiIiKiatJ6+U2pVCIgIIDBjoiIiOgZpnW469mzJw4fPlyXtRARERFRDWl9WvbDDz9EaGgoZs6cCT8/P1hbW0MikZSZ16lTp1otkIiIiIi0p3W4u3btGu7fv48dO3Zg586dZbYLISCRSJCWllarBRIRERGR9rQOd/Pnz8c///yD8ePHo23btqhXr0pPUSEiIiIiHdA6oZ0/fx5Tp07FG2+8UZf1EBEREVENaH1DRdOmTflsOyIiIqJnnNZpbcKECfj2229x4cKFuqyHiIiIiGpA69Oy6enpkEqlGDBgAFq1aoUmTZrAyMhIYw5/foyIiIhIv7QOd8nJyZBKpWjatCmKiopw/fr1uqyLiIiIiKpB63C3f//+uqyDiIiIiGpBlZ9nolKpkJqaiqtXr8LY2BjNmjWDk5NTXdRGRERERFVUpXCXnJyMefPm4ebNmxBCAHh0nd1LL72Ejz76CD4+PnVSJBERERFpR+u7ZY8dO4a3334bQghMnz4dy5Ytw9KlSzF9+nRIJBJMmzYNKSkp1S5k6tSp6N27t8bYwYMHERQUBDc3N/j4+CAhIaHM+06dOoXg4GAoFAr06NEDUVFRKCoqqnYdRERERM8zrVfuYmNj0aJFCyQlJUEmk2lse/311xEUFIS4uDh8/fXXVS5i27Zt2Lt3L1q3bq0eS0lJwaRJkxAYGIiwsDAcP34ckZGREEJg/PjxAIDMzEyMHTsWCoUCS5YswcWLFxEdHQ2lUom5c+dWuQ4iIiKi553W4e7kyZOYMmVKmWAHABYWFhg6dGi1gt3Nmzfx6aefomnTphrjMTExcHR0xOLFiwEAnp6eKC4uxldffYXg4GAYGxsjPj4eMpkMy5cvh7GxMby8vGBqaopPPvkEb775JmxtbatcDxEREdHzrNZ+ckIikVTrdOgHH3yA7t27o2vXruqxgoICHDt2DP7+/hpzAwIC8M8//6hP/x46dAje3t4wNjZWz+nTpw9UKhUOHjxYzW9CRERE9PzSOty5ubkhKSkJ+fn5ZbYplUokJibCxcWlSh+emJiI06dP48MPP9QYz87ORlFREezs7DTG27RpAwDIyMjAgwcPcP369TJzrKysYGFhgYyMjCrVQkRERGQItD4tO3XqVISEhKBfv34YPXo02rZtCwC4dOkSNmzYgJs3b2LevHlaf/DVq1excOFCLFy4EFZWVhrb7t+/D+DR6d7HmZubA3gUJiuaUzpPqVRqXQsRERGRodA63Hl4eCA2Nhbz589HZGQkJBIJAEAIARsbG0RHR6NLly5a7UsIgffffx9eXl4ICAgodzsA9Wc8SSqVPnWOEAJSadXPOFtblw2Kzysbm7LXRlLdYb91i/3WLfZbt9hv3Xq83yI3HzIL0xrv08zMBDZWZjXeT3VV6Tl3vr6+6NWrF06fPo0rV64AAFq0aAEnJyfUq6f9rtavX4+zZ8/ixx9/RHFxMYD/Bbri4mL1TRtPrr6VvpbJZOoVu/JW6PLz88u98aMyOTlKlJSIKr/vWWNjI8Pt2/f1XcYLg/3WLfZbt9hv3WK/devJfucXFOO+8mGN95ufX4DbKlWN91MRqVTy1AWpKv9ChZGREVxdXeHq6oqcnBw0btwYRkZGVdrH7t278ffff6NHjx5ltjk5OeHjjz+GkZERsrKyNLaVvrazs4O5uTlsbW2RmZmpMScnJwdKpbLMtXhEREREL4JKz12uW7cO/fv3V6+wPW7BggXo2bMnvvnmmyp96Lx585CUlKTxx9vbG02bNkVSUhL69OkDDw8P7NmzR72iBzwKhTKZDM7OzgCA7t27Izk5GYWFhRpzjIyM0Llz5yrVRERERGQIKly5E0Jg1qxZ2L59Oxo1aoRr165pPGQYAFq2bAmpVIpFixbh5MmTiIqK0upD27VrV2ascePGMDY2Vt9xO3nyZISGhmL69OkYPHgwTpw4gVWrVmHmzJlo0KABAGDChAnYsWMHJk6ciDFjxuDy5cuIiorC8OHD0bx5c62bQERERGQoKly5S0xMxPbt2/H666/j119/LRPsAGD69On4+eefMXDgQOzatQtbt26ttcK6du2K2NhYXLx4EVOmTMGPP/6I9957D2+88YZ6Tvv27ZGQkID8/HxMmzYNq1evRmhoKObMmVNrdRARERE9TyTi8fOejxk2bBhMTU2xdu3aSndSUlKCoKAgmJiYYNOmTbVepK7whgqqDvZbt9hv3WK/dYv91q0n+51XUIyjaTdrvN9OHWxhblLl2xq0VtkNFRWu3F24cAG+vr5afogUAQEBOHv2bNUrJCIiIqJaU2G4MzIy0vhZr8pYWlpW69lyRERERFR7Kkxjbdq0QWpqqtY7OnXqFG9iICIiItKzCsNd37598eOPP+L8+fOV7uT8+fP48ccf4enpWavFEREREVHVVBjuRowYgebNmyM4OBjbt2+HqpwnLZeUlOA///kPQkNDYW5ujjFjxtRpsURERET0dBXeymFubo64uDi89dZbmDVrFubNmwcnJyfY2NigpKQEOTk5OH36NPLz89GsWTMsW7YML730ki5rJyIiIqInPPU+3Xbt2mH79u1Yv349duzYgZSUFPUvVdSvXx/u7u7w9/fHiBEjqnTzBRERERHVjUofwmJsbIzQ0FCEhoYCAHJzc2FkZIRGjRrVeXFEREREVDVVfsKelZVVXdRBRERERLWAD6YjIiIiMiAMd0REREQGhOGOiIiIyIBUGO42btyIy5cv67AUIiIiIqqpCsNdZGQkjh07pn7t6+uLn3/+WSdFEREREVH1VHi3rLGxMfbt2wd3d3c0aNAAV69exbVr13Dt2rWn7pC/L0tERESkPxWGu6FDh2LVqlX45ZdfAAASiQQLFizAggULnrrDtLS02q2QiIiIiLRWYbh799130alTJ5w9exaFhYVYtmwZevfuDXt7e13WR0RERERV8NSHGPfq1Qu9evUCAGzZsgWDBg2Cr6+vLuoiIiIiomrQ+hcq9u/fDwBQqVRITU3F1atXYWxsjKZNm8LZ2bnOCiQiIiIi7VXp58eSk5Mxb9483Lx5E0IIAI+uxXvppZfw0UcfwcfHp06KJCIiIiLtaB3ujh07hrfffhvW1taYPn062rdvDyEELl26hA0bNmDatGlYs2YNOnbsWJf1EhEREdFTaB3uYmNj0aJFCyQlJUEmk2lse/311xEUFIS4uDh8/fXXtV4kEREREWlH658fO3nyJIYNG1Ym2AGAhYUFhg4dir/++qtWiyMiIiKiqqm135aVSCQoKiqqrd0RERERUTVoHe7c3NyQlJSE/Pz8MtuUSiUSExPh4uJSq8URERERUdVofc3d1KlTERISgn79+mH06NFo27YtAKhvqLh58ybmzZtXV3USERERkRa0DnceHh6IjY3F/PnzERkZCYlEAgAQQsDGxgbR0dHo0qVLnRVKRERERJWr0nPufH190atXL5w+fRpXrlwBALRo0QJOTk6oV69KuyIiIiKiOlDlRGZkZARXV1e4urrWRT1EREREVAO1drcsEREREekfwx0RERGRAWG4IyIiIjIgDHdEREREBkTrcBcSEoLff/9d/VqpVCIkJARnzpypk8KIiIiIqOoqvFu2Z8+ecHJygpOTExwdHXHkyBEMHz5cvb2oqAhHjhzBvXv3dFIoEREREVWuwnA3fvx4pKWlYc+ePVixYgUkEgnmz5+P7777Dh06dECrVq0gkUjUDzMmIiIiIv2rMNyNHTtW/d+FhYVwdXVFr169YG5ujpMnTyIpKQlCCEyaNAkdOnSAs7MzXFxcMGDAAF3UTURERETl0OohxsbGxgAenart378/ACA3NxfdunXD6NGjoVKpcPr0aWzbto3hjoiIiEiPKgx3w4cPR4cOHeDk5AQHBwcA0DgFW/rf3bt3R9euXeu4TCIiIiLSRoXhrlOnTkhPT8fevXuRm5sLiUSCJUuW4JdffoGDgwOaN2/Oa+6IiIiInjEVhrt3331X/d83btxAr1698PLLL+Phw4fYtGkTrly5AgCYNWsW3Nzc4OzsDGdnZ3Tr1q3uqyYiIiKicml1zV3Tpk0BAK+++qr6mrtr167Bx8cHnp6eePDgAb7//nssWbKEz70jIiIi0iOtwh0ANG/eHGZmZurXFhYWaN68OYYMGQKFQgHg0YONiYiIiEh/tA53+/fv13jdsGHDMmMWFha1UxURERERVQt/W5aIiIjIgDDcERERERkQhjsiIiIiA8JwR0RERGRAGO6IiIiIDIhew11JSQk2btyI/v37Q6FQwM/PDwsXLtR4pMrBgwcRFBQENzc3+Pj4ICEhocx+Tp06heDgYCgUCvTo0QNRUVEoKirS5VchIiIieiZo/SiUurBy5UosWbIE48ePR9euXZGRkYGYmBhcuHABq1atQkpKCiZNmoTAwECEhYXh+PHjiIyMhBAC48ePBwBkZmZi7NixUCgUWLJkCS5evIjo6GgolUrMnTtXn1+PiIiISOf0Fu6EEFi5ciVGjBiBmTNnAgC6desGS0tLTJ8+HWlpaYiJiYGjoyMWL14MAPD09ERxcTG++uorBAcHw9jYGPHx8ZDJZFi+fDmMjY3h5eUFU1NTfPLJJ3jzzTdha2urr69IREREpHN6Oy2bl5eHAQMGoF+/fhrj7dq1AwCcP38ex44dg7+/v8b2gIAA/PPPP0hJSQEAHDp0CN7e3jA2NlbP6dOnD1QqFQ4ePFjH34KIiIjo2aK3lTsLCwt88MEHZcb37dsHAHB0dERRURHs7Ow0trdp0wYAkJGRATc3N1y/fr3MHCsrK1hYWCAjI6OOqiciIiJ6Nj1Td8v+9ddfiI+Ph5+fH+7fvw+g7E+amZubA3j0O7YVzSmdx9+6JSIioheNXm+oeNzx48cxadIktGzZEp988ol61U0ikZQ7XyqVQghR4RwhBKTSqmVXa2vD+W1cGxuZvkt4obDfusV+6xb7rVvst2493m+Rmw+ZhWmN92lmZgIbK7Ma76e6nolwt3PnTsyePRtt27bFypUrYWlpiTt37gBAmdW30tcymUy9YlfeCl1+fj5ksqr9DyQnR4mSElGdr/BMsbGR4fbt+/ou44XBfusW+61b7Ldusd+69WS/8wuKcV/5sMb7zc8vwG2Vqsb7qYhUKnnqgpTeT8uuXr0aM2bMgLu7O9avX4+XXnoJANC6dWsYGRkhKytLY37pazs7O5ibm8PW1haZmZkac3JycqBUKstci0dERERk6PQa7hITE/HZZ58hMDAQK1eu1FhpMzExgYeHB/bs2aM+/QoAu3fvhkwmg7OzMwCge/fuSE5ORmFhocYcIyMjdO7cWXdfhoiIiOgZoLfTsjk5Ofj000/RokULjBo1CmfOnNHY3rp1a0yePBmhoaGYPn06Bg8ejBMnTmDVqlWYOXMmGjRoAACYMGECduzYgYkTJ2LMmDG4fPkyoqKiMHz4cDRv3lwfX42IiIhIb/QW7n777Tc8ePAAV69exahRo8psj4yMxMCBAxEbG4uYmBhMmTIFtra2eO+99zBu3Dj1vPbt2yMhIQGRkZGYNm0aLC0tERoairfffluXX4eIiIjomSARj5/zfMHxhgqqDvZbt9hv3WK/dYv91q0n+51XUIyjaTdrvN9OHWxhblJ362fP/A0VRERERFR7GO6IiIiIDAjDHREREZEBYbgjIiIiMiAMd0REREQGhOGOiIiIyIAw3BEREREZEIY7IiIiIgPCcEdERERkQBjuiIiIiAwIwx0RERGRAWG4IyIiIjIgDHdEREREBoThjoiIiMiAMNwRERERGRCGOyIiIiIDwnBHREREZEAY7oiIiIgMCMMdERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQhjsiIiIiA8JwR0RERGRAGO6IiIiIDAjDHREREZEBYbgjIiIiMiAMd0REREQGhOGOiIiIyIAw3BEREREZEIY7IiIiIgPCcEdERERkQBjuiIiIiAwIwx0RERGRAWG4IyIiIjIgDHdEREREBoThjoiIiMiAMNwRERERGRCGOyIiIiIDwnBHREREZEAY7oiIiIgMCMMdERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQhjsiIiIiA8JwR0RERGRADCbc/ec//0Hfvn3h6uqKwMBAbN26Vd8lEREREemcQYS7Xbt24Z133kH37t2xbNkydO7cGbNmzcJPP/2k79KIiIiIdKqevguoDVFRUQgMDMT7778PAOjZsyfu3buHL7/8En369NFzdURERES689yv3GVnZyMrKwv+/v4a4wEBAbh06RKys7P1VBkRERGR7j33K3eXLl0CANjZ2WmMt2nTBgCQkZGBVq1aabUvqVRSu8XpkSF9l+cB+61b7Ldusd+6xX7r1uP9rmckhZlp/Rrvs56RtE7/71jZvp/7cHf//n0AgIWFhca4ubk5AECpVGq9L0tL89orTM+srS0qn0S1hv3WLfZbt9hv3WK/devJfrds1khPldSe5/60rBACACCRSModl0qf+69IREREpLXnPvnIZDIAZVfo8vLyNLYTERERvQie+3BXeq1dVlaWxnhmZqbGdiIiIqIXwXMf7tq0aYOWLVuWeabdnj170LZtWzRv3lxPlRERERHp3nN/QwUATJkyBREREWjUqBF69eqF/fv3Y9euXYiOjtZ3aUREREQ6JRGldx485zZt2oSEhARcv34drVq1wsSJEzFo0CB9l0VERESkUwYT7oiIiIjIAK65IyIiIqL/YbgjIiIiMiAMd8+BkpISbNy4Ef3794dCoYCfnx8WLlyo8Wy/3r17w97evsyf3Nxc9ZxTp04hODgYCoUCPXr0QFRUFIqKivTxlZ5pQgh88803CAgIgKurKwYMGIAff/xRY87BgwcRFBQENzc3+Pj4ICEhocx+2G/taNNvHt91Y+rUqejdu7fGGI/tulNev3ls167i4mK4urqW6adCoVDPeRGOcYO4W9bQrVy5EkuWLMH48ePRtWtXZGRkICYmBhcuXMCqVauQl5eH7OxszJw5E507d9Z4b8OGDQE8eu7f2LFjoVAosGTJEly8eBHR0dFQKpWYO3euPr7WM2vFihWIiYnB22+/DXd3d/z666945513YGRkhFdffRUpKSmYNGkSAgMDERYWhuPHjyMyMhJCCIwfPx4A+10VlfWbx3fd2LZtG/bu3YvWrVurx3hs153y+s1ju/ZlZGSgoKAAixYtQtu2bdXjpb9W9cIc44KeaSUlJaJTp07i448/1hjfsWOHkMvl4syZM+L48eNCLpeLCxcuVLif999/X3h5eYmCggL12Pr160WHDh3EjRs36qz+501hYaHo1KmTmD9/vsb46NGjxWuvvSaEEGLMmDFi2LBhGtsjIyOFh4eHur/st3a06TeP79p348YN0alTJ+Hp6Sn8/PzU4zy260ZF/eaxXfu2b98uHBwcRH5+frnbX5RjnKdln3F5eXkYMGAA+vXrpzHerl07AI9+mSMtLQ0mJiYa/0p50qFDh+Dt7Q1jY2P1WJ8+faBSqXDw4ME6qf15ZGRkhLVr12LixIka4/Xr10dBQQEKCgpw7Ngx+Pv7a2wPCAjAP//8g5SUFADst7Yq6zcAHt914IMPPkD37t3RtWtX9RiP7bpTXr8BHtt1IS0tDa1bt0aDBg3KbHuRjnGGu2echYUFPvjgA7zyyisa4/v27QMA/Otf/8LZs2fRuHFjzJgxAx4eHlAoFJg+fTpu374NAHjw4AGuX79e5qfYrKysYGFhgYyMDN18meeAVCqFvb09bG1tIYTAnTt3EB8fj//+978YMWIEsrOzUVRUVKaXbdq0AfDolAD7rb3K+g2Ax3ctS0xMxOnTp/Hhhx9qjPPYrhsV9RvgsV0Xzp49C2NjY4wfPx4KhQKdOnXC3LlzoVQqX6hjnNfcPYf++usvxMfHw8/PD+3bt0d6ejru3LmDl19+GcHBwbh06RJiYmIQEhKCLVu24P79+wAeBcUnmZuba9yYQf+zZ88eTJs2DQDQq1cvDBgwAGlpaQDK9tLc3BwAoFQq2e9qKq/fAHh816KrV69i4cKFWLhwIaysrDS2VdRHHtvV97R+Azy260J6ejqUSiWGDRuGSZMmITU1FbGxscjIyMCMGTMAvBjHOMPdc+b48eOYNGkSWrZsiU8++QTAoyV/IQTc3NwAAB4eHmjfvj1ef/11bN++HV5eXgAAiURSZn9CCPWFpqTJ0dER69atw9mzZ/Hll19i4sSJCA8PB1B+L4FHK1Hi/z8XnP2umvL6vWbNGh7ftUQIgffffx9eXl4ICAgodzvAY7u2VNZvgH9314Xo6Gg0atQI9vb2AIBOnTrB2toa7777Lg4dOgTgxTjGGe6eIzt37sTs2bPRtm1brFy5EpaWlgAAV1fXMnNfeeUVyGQypKeno2/fvgBQ7r848vPzIZPJ6rbw51SrVq3QqlUrdOrUCRYWFpg1a5b6f/hP9rL0tUwmU/+Lj/2umvL6feLECY1HGJTi8V1169evx9mzZ/Hjjz+iuLgYwP8CXXFxsbpPPLZrR2X9NjIy4t/ddeDJu46BR2cCHvciHOMMd8+J1atXY9GiRejcuTOWLVumPsDy8/Oxa9cuODk5wcHBQT1fCIGioiJYWlrC3Nwctra2yMzM1NhnTk4OlEplmWsLXmR3797FgQMH0LVrV9ja2qrHHR0dAQBXrlyBkZERsrKyNN5X+trOzo79roLK+n358mVcunSJx3ct2L17N/7++2/06NGjzDYnJyd8/PHHPLZrUWX9njt3LkxNTXls16KcnBzs378fXbp0QatWrdTjDx8+BABYW1u/MMf487G++IJLTEzEZ599hsDAQKxcuVLjXw4mJiZYtGgRli5dqvGen3/+GQ8fPlT/K6Z79+5ITk5GYWGhes7u3bthZGRU7r90XlQlJSWYPXs2Nm/erDFeupzv4uICDw8P7NmzR/2vcOBRL2UyGZydnQGw39qqrN9ubm48vmvJvHnzkJSUpPHH29sbTZs2RVJSEvr06cNjuxZV1u9XX32Vx3Ytk0gkmDt3LtatW6cxvnPnThgZGaFbt24vzjGuq2euUPXcuXNHuLm5CW9vb3H06FFx4sQJjT85OTkiISFByOVy8e9//1scOnRIrF69WnTs2FFMnjxZvZ8LFy4IFxcXMWbMGLF//36RkJAgnJ2dxUcffaS/L/eMmjdvnnBychIrVqwQ//3vf0VsbKxwdnYWc+bMEUII8d///lfY29uLsLAwceDAAREdHS3s7e1FfHy8eh/st/Yq6zeP77oza9Ysjeeu8diuW0/2m8d27fv3v/8tOnToIGJiYtR/nzg5OYlPPvlECPHiHOMMd8+4LVu2CLlcXuGfrVu3CiGE+O6770S/fv2Eq6ur6Nmzp4iMjBQPHjzQ2NfRo0fFsGHDhLOzs+jZs6f44osvRGFhoT6+1jOtsLBQxMfHC39/f+Hs7Cz8/PzEihUrhEqlUs/Zs2eP6Nevn3BychI+Pj5i1apVZfbDfmtHm37z+K4bT4YNIXhs16Xy+s1ju3aV/n0SEBAgnJ2dha+v7wv597dEiMfWJomIiIjoucZr7oiIiIgMCMMdERERkQFhuCMiIiIyIAx3RERERAaE4Y6IiIjIgDDcERERERkQhjsiIiIiA8JwR0R1QqlUIiEhAUOGDMErr7wCd3d3DB06FJs3b0ZJSYm+y9O77OzsSucEBwfD3t5eB9VUn1KpRG5urvr17Nmzn/maiQwdwx0R1bpLly4hKCgIUVFRsLe3x4wZMzBt2jSYmJhg7ty5eO+99/AiPz99+fLlGDdunL7LqLHU1FQEBgbi/Pnz+i6FiB5TT98FEJFhKSgowFtvvYW7d+8iKSkJDg4O6m3jxo3DvHnzsGHDBri6uiIkJESPlerP77//DpVKpe8yauzcuXO4deuWvssgoidw5Y6IatWGDRuQkZGBiIgIjWBXatasWWjUqBE2bdqkh+qIiAwfwx0R1aodO3bAzMwMffv2LXe7qakpvvvuO2zdulVj/NixYxg7diwUCgUUCgVCQkJw9OhRjTk+Pj6YP38+EhMTERAQAFdXVwQFBeHkyZO4ffs2wsLCoFAo0LNnT0RHR2tc22dvb4+vv/4a8fHx6NWrF9zc3BAcHIzMzExkZGRg/PjxcHd3h4+PD9asWVOm7h9++AGDBg2Ci4sLunTpgtmzZ2usWl25cgX29vbYunUroqOj4enpCRcXFwwbNgyHDx/W+A5HjhzB1atXYW9vj9jY2Oq0uYwTJ04gNDRU3b9x48bh5MmTZfo3d+5cbNu2DX379oWLiwv8/f2xfv36Mvv75ZdfMGzYMLi7u8PX1xfr1q3DnDlz4OPjAwCIjY1FREQEACAkJEQ9XurUqVMIDg6Gq6srunfvjgULFqCgoKBWvisRPZ1EvMgXvhBRrRJCwNnZGR07dsTatWu1ft/PP/+MqVOnonXr1ggKCgIAJCYm4tq1a4iJiYGvry+AR+FEpVJBpVJhzJgxEEIgLi4ODRs2hEwmw8svv4wuXbpgz549OHjwID777DMMHjwYwKNwZ2triwYNGmDUqFHIycnBypUr0b59e9y9exe9evWCo6MjEhMTkZqairVr16Jz584AgKVLlyI2NhYBAQHo0qULbt68iXXr1qFRo0ZISkqClZUVrly5Al9fXzRv3hwNGjTA8OHDUVRUhISEBOTn5+PAgQOwtLTEvn378MUXX+Dvv/9GREQE7O3ty13hBB7dUHHkyBGcPXv2qf07dOgQ3nzzTTg4OKBfv34oLCzEDz/8gKtXr2L16tXw8PBQ908Igby8PIwePRpNmjTB5s2bkZ6ejvj4eHh5eQEAkpOTMWXKFMjlcgwePBg3b97E2rVrYWZmBnNzc+zfvx/p6enYsGEDNm/ejEmTJsHFxQV+fn6YPXs2tmzZAnNzcwwYMAAODg44cOAAkpOTERISgjlz5mh9XBBRNQkiolqSk5Mj5HK5mD59utbvKSoqEp6ensLLy0vcv39fPX7v3j3Rs2dP0bNnT1FYWCiEEMLb21vY29uL9PR09bxFixYJuVwuwsPD1WN5eXnCyclJzJgxQz0ml8uFm5ubuH37tnps2rRpQi6Xi8WLF6vHLl++LORyuYiKihJCCJGVlSUcHBzE559/rlH32bNnhZOTk/j000+FEEJkZ2cLuVwuvLy8RF5ennrejh07hFwuF5s3b1aPjR49Wnh7e1fam9GjRwu5XP7UOSqVSvj6+oqRI0eK4uJijR707t1bDBw4UD1W2r+0tDT12K1bt4S9vb1Gr/z8/IS/v7948OCBemzv3r1CLpdr1P39998LuVwuDh8+rB6bNWuWkMvlYvXq1Ro19u7dW3h5eVX6nYmo5nhalohqjVT66K+UqtwscObMGdy4cQOjRo2ChYWFerxhw4YYPXo0bt68idTUVPV469atNR61YWdnBwDo3bu3eszMzAzW1ta4ffu2xmcpFAo0adJE/bpt27Zl3tuyZUsAUJ9y3bt3L0pKSuDj44Pc3Fz1nyZNmqBDhw44cOCAxmd4eXnBzMxM/bp0Ve7JWmrLmTNnkJ2dDT8/P9y7d09d38OHD+Ht7Y20tDTcuHFDPd/Ozk5jpdDGxgZNmjTBnTt3AADp6enIysrCyJEjYWpqqp7n5+eH9u3ba13X46flpVIpHB0d1Z9BRHWLd8sSUa1p1KgR6tevr/Hcs8pcuXIFwP9C2uPatWsHALh27RoUCgUAwNraWmOOkZERAMDKyqrMuHjiqpMn31uvXr0y7y3dX+l7s7KyAAAjR44st/769etrvH6yDmNjYwCos2f7ldYXGRmJyMjIcudcv34dTZs2Lbe+0hpL68vMzAQAtGnTpsw8Ozs7pKWlaVXXk702NTVFUVGRVu8lopphuCOiWiORSKBQKJCamori4mJ1eHpSdHQ0srOzERER8dTn3ZVuezxAVbRPiURSaX3VeW9p6ImLi9NYyapI6eqlrpTWFxYWBnd393LnlIZkoPL6iouLAfwvlD7OxMRE67p03Qci+h+GOyKqVb1798aRI0ewc+dODBgwoMz2hw8fIikpCSqVCo0bN0aLFi0APHrw8ZMyMjIAQL3qpA+l9TVr1gwdOnTQ2PbLL79onErWh9L6zMzM0K1bN41tJ0+exL1797QKpaVatWoFALh8+TJ69Oihse3y5cs1K5aIdIL/tCKiWjVixAi0aNECixYtwrlz5zS2qVQqfPzxx7hz5w7eeOMN1K9fH05OTrCxscHGjRuhVCrVc5VKJTZs2AAbGxs4Ozvr+muoeXt7AwBWrFihscqYlpaGyZMn49tvv63yPqVSaa2dpnV2doaNjQ3Wrl2LvLw89bhSqUR4eDgiIiLUp5q13V+zZs2QlJSEwsJC9fiff/6JM2fOaMwtXZ3jz8kRPVu4ckdEtcrExARLly7FuHHjMHToUPTv3x8uLi64e/cufvrpJ6SlpaFPnz4IDQ0F8OiU64cffojw8HAEBQVh6NChAICkpCTcunULMTExej3FJ5fLERwcjLVr1+Lu3bvw8/PD3bt3sW7dOpibmyMsLKzK+7SyssLRo0exevVqdOzYEW5ubk+dP3fu3HLHX3/9dTg4OKj7N2TIEAwdOhQmJibqR8l8/vnnFZ6OLo9UKsXs2bMRHh6OkSNHYuDAgcjNzcWaNWvKnKotvX5v48aNuHPnDvr376/15xBR3WG4I6Ja5+joiG3btuGbb77Br7/+ip07d0IIAXt7eyxYsABDhgzRuM4tICAACQkJWL58OZYtW4Z69erBzc0Nn376qfoZbfo0Z84ctGvXDps2bcKiRYsgk8ng4eGBsLCwKt1BWmrChAk4e/YsvvjiCwwZMqTScLd58+Zyxz09PeHg4KDuX1xcHJYvXw6pVIqXX34ZcXFx6pXHqujTpw+io6MRFxeHxYsXw9bWFhEREdi6davGzTJdu3ZFYGAgkpOTcfjwYfj7+1f5s4io9vEhxkREpKZSqXDv3r1y76rt378/GjZsWO4vWhDRs4PX3BERkZpKpYKnp2eZU8Hnzp3D+fPn4erqqqfKiEhbPC1LRERqxsbG6NOnD5KSkiCRSODs7Ixbt25h48aNsLS0VF8rSUTPLp6WJSIiDQ8fPsSqVauwfft2XL9+HTKZDF27dkV4eLj6FzyI6NnFcEdERERkQHjNHREREZEBYbgjIiIiMiAMd0REREQGhOGOiIiIyIAw3BEREREZkP8HprsHbcRN+TEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.chdir(\"\")\n",
    "\n",
    "import helper_functions as hf\n",
    "\n",
    "data = pd.read_csv(\"merged_speeches_populism_v2.csv\") # use \n",
    "len(data)\n",
    "data[\"text\"] = [i.replace(\"\\n\", \" \") for i in data[\"text\"]]\n",
    "var = 'speechtype' # set main variable to be used for classification\n",
    "data[var].value_counts()\n",
    "data[\"label\"] = data[var].astype('category')\n",
    "data[\"label\"] = data[\"label\"].cat.codes\n",
    "data.columns\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data[\"label\"].value_counts()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\", do_lower_case=True)\n",
    "\n",
    "input_ids = []\n",
    "lengths = []\n",
    "for x, row in data.iterrows():\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        row['text'],                      \n",
    "                        add_special_tokens = True,\n",
    "                   )\n",
    "    input_ids.append(encoded_sent)\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "print('{:>10,} comments'.format(len(input_ids)))\n",
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(np.median(lengths)))\n",
    "\n",
    "hf.plot_distribution(lengths)\n",
    "\n",
    "max_len = 512 #max(lengths)\n",
    "\n",
    "num_truncated = np.sum(np.greater(lengths, max_len))\n",
    "num_sentences = len(lengths)\n",
    "prcnt = float(num_truncated) / float(num_sentences)\n",
    "print('{:,} of {:,} sentences ({:.1%}) in the training set are longer than {:} tokens.'.format(num_truncated, num_sentences, prcnt, max_len))\n",
    "\n",
    "# create tokenized data\n",
    "labels = []\n",
    "input_ids = []\n",
    "attn_masks = []\n",
    "\n",
    "for x, row in data.iterrows():\n",
    "    encoded_dict = tokenizer.encode_plus(row['text'],\n",
    "                                              max_length=max_len, #see other code for how to set this\n",
    "                                              padding='max_length',\n",
    "                                              truncation=True,\n",
    "                                              return_tensors='pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attn_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(row['label'])\n",
    "\n",
    "\n",
    "# Convert into tensor matrix.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attn_masks = torch.cat(attn_masks, dim=0)\n",
    "\n",
    "# Labels list to tensor.\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attn_masks, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Specify key model parameters here: \n",
    "model_name = \"bert-base-multilingual-uncased\"\n",
    "lr = 3e-5\n",
    "epochs = 6\n",
    "batch_size = 32 # 50-60GB with 512 tokens and 32 batch size\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 6\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "torch.cuda.empty_cache() #Clear GPU cache if necessary\n",
    "\n",
    "training_stats = [] # Store training and validation loss,validation accuracy, and timings.\n",
    "fold_stats = []\n",
    "\n",
    "total_t0 = time.time() # Measure the total training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== #\n",
    "#              CV Training                 #\n",
    "# ======================================== #\n",
    "\n",
    "# repeat 10 times  \n",
    "\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H%M')\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    \n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler)\n",
    "    \n",
    "    # Initiate model parameters for each fold\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "    device = torch.device('cuda:0')\n",
    "    desc = model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr = lr, eps = 1e-6) \n",
    "    total_steps = (int(len(dataset)/batch_size)+1) * epochs \n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
    "          \n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0 # Reset the total loss for this epoch.\n",
    "        model.train() # Put the model into training mode.\n",
    "        update_interval = hf.good_update_interval( # Pick an interval on which to print progress updates.\n",
    "                    total_iters = len(train_dataloader),\n",
    "                    num_desired_updates = 10\n",
    "                )\n",
    "\n",
    "        predictions_t, true_labels_t = [], []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if (step % update_interval) == 0 and not step == 0:\n",
    "                elapsed = hf.format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed), end='\\r')\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            # Always clear any previously calculated gradients before performing a backward pass.\n",
    "            model.zero_grad()\n",
    "            # Perform a forward pass --returns the loss and the \"logits\"\n",
    "            loss = model(b_input_ids,\n",
    "                               attention_mask=b_input_mask,\n",
    "                               labels=b_labels)[0]\n",
    "            logits = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)[1]\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "            total_train_loss += loss.item()\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "            # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            optimizer.step()\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "            \n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # Store predictions and true labels\n",
    "            predictions_t.append(logits)\n",
    "            true_labels_t.append(label_ids)\n",
    "\n",
    "        # Combine the results across all batches.\n",
    "        flat_predictions_t = np.concatenate(predictions_t, axis=0)\n",
    "        flat_true_labels_t = np.concatenate(true_labels_t, axis=0)\n",
    "        # For each sample, pick the label (0, 1) with the highest score.\n",
    "        predicted_labels_t = np.argmax(flat_predictions_t, axis=1).flatten()        \n",
    "        acc_t = accuracy_score(predicted_labels_t, flat_true_labels_t)\n",
    "        \n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = hf.format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        print(\"  Training accuracy: {:.3f}\".format(acc_t))\n",
    "        \n",
    "        if acc_t > 0.9 and epoch_i >= 3:\n",
    "            break        \n",
    "\n",
    "    # TEST\n",
    "    # After the completion of each training epoch, measure our performance on our test set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running test...\")\n",
    "    t0 = time.time()\n",
    "    model.eval() # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "    total_eval_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            loss = model(b_input_ids,\n",
    "                               attention_mask=b_input_mask,\n",
    "                               labels=b_labels)[0]\n",
    "            logits = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)[1]\n",
    "        # Accumulate the test loss.\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Store predictions and true labels\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    # Combine the results across all batches.\n",
    "    flat_predictions = np.concatenate(predictions, axis=0)\n",
    "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "    # For each sample, pick the label (0, 1) with the highest score.\n",
    "    predicted_labels = np.argmax(flat_predictions, axis=1).flatten()\n",
    "    # Calculate the test accuracy.\n",
    "    val_accuracy = (predicted_labels == flat_true_labels).mean()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    \n",
    "    ov_acc = [accuracy_score(predicted_labels, flat_true_labels), recall_score(predicted_labels, flat_true_labels, average=\"macro\"), precision_score(predicted_labels, flat_true_labels, average=\"macro\"),f1_score(predicted_labels, flat_true_labels, average=\"macro\")]\n",
    "    f1 = list(f1_score(flat_true_labels,predicted_labels,average=None))\n",
    "    matrix = confusion_matrix(flat_true_labels,predicted_labels)\n",
    "    acc = list(matrix.diagonal()/matrix.sum(axis=1))\n",
    "    cr = pd.DataFrame(classification_report(pd.Series(flat_true_labels),pd.Series(predicted_labels), output_dict=True)).transpose().iloc[0:4, 0:2]\n",
    "    prec =list(cr.iloc[:,0])\n",
    "    rec = list(cr.iloc[:,1]) \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"Campaign (0): {0:.3f}\".format(acc[0]))\n",
    "    print(\"Famous (1): {0:.3f}\".format(acc[1]))\n",
    "    print(\"International (2): {0:.3f}\".format(acc[2]))\n",
    "    print(\"Ribboncutting (3): {0:.3f}\".format(acc[3]))\n",
    "    print('mBERT Prediction accuracy: {:.3f}'.format(val_accuracy))\n",
    "    \n",
    "    # Measure how long the test run took.\n",
    "    test_time = hf.format_time(time.time() - t0)\n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))        \n",
    "\n",
    "    fold_stats.append(\n",
    "        {\n",
    "            'fold': fold+1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Test Loss': avg_val_loss,\n",
    "            'Test Accur.': ov_acc[0],\n",
    "            'Campaign (0) Accur.': acc[0],\n",
    "            'Famous (1) Accur.': acc[1],\n",
    "            'International (2) Accur.': acc[2],\n",
    "            'Ribboncutting (3) Accur.': acc[3],\n",
    "            'f1': [f1, ov_acc[3]],\n",
    "            'prec': [prec, ov_acc[2]],\n",
    "            'rec': [rec, ov_acc[1]]\n",
    "        }\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechtype_stats = []\n",
    "speechtype_stats.append(\n",
    "    {\n",
    "        'Model': model_name,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "\n",
    "        'Campaign_mean': np.mean([x['Campaign (0) Accur.'] for x in fold_stats ]),\n",
    "        'Campaign_mean_sd': np.std([x['Campaign (0) Accur.'] for x in fold_stats ]),\n",
    "        'Campaign_mean_f1': np.mean([x['f1'][0][0] for x in fold_stats ]),\n",
    "        'Campaign_mean_f1_sd': np.std([x['f1'][0][0] for x in fold_stats ]),\n",
    "        'Campaign_recall': np.mean([x['rec'][0][0] for x in fold_stats ]),\n",
    "        'Campaign_recall_sd': np.std([x['rec'][0][0] for x in fold_stats ]),\n",
    "        'Campaign_prec': np.mean([x['prec'][0][0] for x in fold_stats ]),\n",
    "        'Campaign_prec_sd': np.std([x['prec'][0][0] for x in fold_stats ]),\n",
    "        \n",
    "        'Famous_mean': np.mean([x['Famous (1) Accur.'] for x in fold_stats ]),\n",
    "        'Famous_mean_sd': np.std([x['Famous (1) Accur.'] for x in fold_stats ]),\n",
    "        'Famous_mean_f1': np.mean([x['f1'][0][1] for x in fold_stats ]),\n",
    "        'Famous_mean_f1_sd': np.std([x['f1'][0][1] for x in fold_stats ]),\n",
    "        'Famous_recall': np.mean([x['rec'][0][1] for x in fold_stats ]),\n",
    "        'Famous_recall_sd': np.std([x['rec'][0][1] for x in fold_stats ]),\n",
    "        'Famous_prec': np.mean([x['prec'][0][1] for x in fold_stats ]),\n",
    "        'Famous_prec_sd': np.std([x['prec'][0][1] for x in fold_stats ]),\n",
    "        \n",
    "        'International_mean': np.mean([x['International (2) Accur.'] for x in fold_stats ]),\n",
    "        'International_mean_sd': np.std([x['International (2) Accur.'] for x in fold_stats ]),\n",
    "        'International_mean_f1': np.mean([x['f1'][0][2] for x in fold_stats ]),\n",
    "        'International_mean_f1_sd': np.std([x['f1'][0][2] for x in fold_stats ]),\n",
    "        'International_recall': np.mean([x['rec'][0][2] for x in fold_stats ]),\n",
    "        'International_recall_sd': np.std([x['rec'][0][2] for x in fold_stats ]),\n",
    "        'International_prec': np.mean([x['prec'][0][2] for x in fold_stats ]),\n",
    "        'International_prec_sd': np.std([x['prec'][0][2] for x in fold_stats ]),\n",
    "        \n",
    "        'Ribboncutting_mean': np.mean([x['Ribboncutting (3) Accur.'] for x in fold_stats ]),\n",
    "        'Ribboncutting_mean_sd': np.std([x['Ribboncutting (3) Accur.'] for x in fold_stats ]),\n",
    "        'Ribboncutting_mean_f1': np.mean([x['f1'][0][3] for x in fold_stats ]),\n",
    "        'Ribboncutting_mean_f1_sd': np.std([x['f1'][0][3] for x in fold_stats ]),\n",
    "        'Ribboncutting_recall': np.mean([x['rec'][0][3] for x in fold_stats ]),\n",
    "        'Ribboncutting_recall_sd': np.std([x['rec'][0][3] for x in fold_stats ]),\n",
    "        'Ribboncutting_prec': np.mean([x['prec'][0][3] for x in fold_stats ]),\n",
    "        'Ribboncutting_prec_sd': np.std([x['prec'][0][3] for x in fold_stats ]),\n",
    "        \n",
    "        'overall_mean': np.mean([x['Test Accur.'] for x in fold_stats ]),\n",
    "        'overall_mean_sd': np.std([x['Test Accur.'] for x in fold_stats ]),\n",
    "        'overall_mean_f1': np.mean([x['f1'][1] for x in fold_stats ]),\n",
    "        'overall_mean_f1_sd': np.std([x['f1'][1] for x in fold_stats ]),\n",
    "        'overall_recall': np.mean([x['rec'][1] for x in fold_stats ]),\n",
    "        'overall_recall_sd': np.std([x['rec'][1] for x in fold_stats ]),\n",
    "        'overall_prec': np.mean([x['prec'][1] for x in fold_stats ]),\n",
    "        'overall_prec_sd': np.std([x['prec'][1] for x in fold_stats ]),\n",
    "    }\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('fold_stats_mbert_' + timestamp + '.txt', 'w') as outfile:\n",
    "  json.dump(fold_stats, outfile)\n",
    "with open('speechtype_results_mbert_' + timestamp + '.txt', 'w') as outfile:\n",
    "  json.dump(speechtype_stats, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
